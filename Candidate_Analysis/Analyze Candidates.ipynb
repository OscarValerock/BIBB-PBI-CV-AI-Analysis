{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder of the desired analysis\n",
    "analysis_folder = \"001_Analysis\"\n",
    "results_folder_path = \"./Candidates Analysis/\" + analysis_folder + \"/Results\"\n",
    "gptModel = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Text Extraction Script\n",
    "\n",
    "This script extracts text from all PDF files within a designated folder and saves the extracted content in a JSON file. It processes every PDF in the folder, stores the filename and corresponding text in a JSON structure, and ensures that the JSON file is overwritten with fresh data each time the script is executed. The output JSON file is saved in the same directory as the PDF files, making it convenient to access the extracted information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been successfully saved to ./Candidates Analysis/001_Analysis/Results\\OCR_Results.json\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = \"./Candidates Analysis/\" + analysis_folder + \"/CV\"\n",
    "\n",
    "# Initialize an empty list to store the extracted text\n",
    "extracted_data = []\n",
    "\n",
    "# Iterate through all the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".pdf\"):  # Process only PDF files\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Open the PDF file\n",
    "        doc = fitz.open(file_path)\n",
    "        \n",
    "        # Extract text from each page\n",
    "        text = \"\"\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            text += page.get_text()\n",
    "        \n",
    "        # Store the extracted text in a dictionary with the filename as key\n",
    "        extracted_data.append({\n",
    "            \"filename\": filename,\n",
    "            \"content\": text\n",
    "        })\n",
    "\n",
    "# Convert the list to JSON format\n",
    "extracted_json = json.dumps(extracted_data, indent=4)\n",
    "\n",
    "# Define the output path to save the JSON file in the same location as the CV folder\n",
    "output_json_path = os.path.join(results_folder_path, \"OCR_Results.json\")\n",
    "\n",
    "# Save the JSON data to a file (this will overwrite the file if it already exists)\n",
    "with open(output_json_path, \"w\") as json_file:\n",
    "    json_file.write(extracted_json)\n",
    "\n",
    "print(f\"JSON data has been successfully saved to {output_json_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Structure for CV Data\n",
    "\n",
    "This Python script defines a JSON structure for storing comprehensive CV (Curriculum Vitae) data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "structure = {\n",
    "    \"content\": {\n",
    "        \"personal_information\": {\n",
    "            \"name\": \"\",\n",
    "            \"phone\": \"\",\n",
    "            \"email\": \"\",\n",
    "            \"location\": { \"city\": \"\", \"countryISO\": \"\", \"countryName\": \"\" }\n",
    "        },\n",
    "        \"CV summary\": \"\",\n",
    "        \"education\": [\n",
    "            {\n",
    "                \"degree\": \"\",\n",
    "                \"institution\": \"\",\n",
    "                \"start_date_YYYY\": \"\",\n",
    "                \"end_date_YYYY\": \"\",\n",
    "                \"sort_order_newest_to_oldest\": \"\",\n",
    "                \"location\": { \"city\": \"\", \"countryISO\": \"\", \"countryName\": \"\" }\n",
    "            }\n",
    "        ],\n",
    "        \"work_experience\": [\n",
    "            {\n",
    "                \"title\": \"\",\n",
    "                \"company\": \"\",\n",
    "                \"start_date_YYYY\": \"\",\n",
    "                \"end_date_YYYY\": \"\",\n",
    "                \"sort_order_newest_to_oldest\": \"\",\n",
    "                \"location\": { \"city\": \"\", \"countryISO\": \"\", \"countryName\": \"\" },\n",
    "                \"responsibilities\": []\n",
    "            }\n",
    "        ],\n",
    "        \"skills\": [],\n",
    "        \"certifications_and_courses\": [],\n",
    "        \"languages\": [{ \"language\": \"\", \"proficiency\": \"\" }],\n",
    "        \"systems_knowledge\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "cvStructure = json.dumps(structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing OCR Results and Summarizing with OpenAI\n",
    "\n",
    "This script integrates OCR results with OpenAI's API to generate structured summaries of the content.\n",
    "\n",
    "This approach ensures that each OCR result is only processed once and stored in a structured format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Alex_Johnson_CV.pdf as it already exists.\n",
      "Skipping Emma_Brown_CV.pdf as it already exists.\n",
      "Skipping John_Carter_CV.pdf as it already exists.\n",
      "Skipping Maria_Thompson_CV.pdf as it already exists.\n",
      "Skipping Michael_Smith_CV.pdf as it already exists.\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Temporarily add the parent directory to the system path to import Constants\n",
    "sys.path.append(\"..\")\n",
    "import Constants\n",
    "sys.path.remove(\"..\")\n",
    "\n",
    "# Initialize OpenAI client with the API key from Constants\n",
    "client = OpenAI(api_key=Constants.OpenAIKey)\n",
    "\n",
    "# Define the paths for the JSON files\n",
    "json_path_OCR_Result = results_folder_path + \"/OCR_Results.json\"\n",
    "json_output_path = results_folder_path + \"/LLM_Normalized_CV.json\"\n",
    "\n",
    "# Load the OCR results from the JSON file\n",
    "with open(json_path_OCR_Result, 'r') as file:\n",
    "    ocr_results = json.load(file)\n",
    "\n",
    "# Load existing responses if the output file already exists\n",
    "if os.path.exists(json_output_path):\n",
    "    with open(json_output_path, 'r') as file:\n",
    "        existing_responses = json.load(file)\n",
    "else:\n",
    "    existing_responses = []\n",
    "\n",
    "# Iterate over each object in the JSON file and send it to the OpenAI API\n",
    "for ocr_object in ocr_results:\n",
    "    filename = ocr_object['filename']\n",
    "    \n",
    "    # Check if the filename already exists in the existing responses\n",
    "    if any(response['filename'] == filename for response in existing_responses):\n",
    "        print(f\"Skipping {filename} as it already exists.\")\n",
    "        continue\n",
    "    \n",
    "    content = ocr_object['content']\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model = gptModel,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant whose job is to perfectly understand the following data\" + content},\n",
    "                {\"role\": \"user\", \"content\": \"You need to summarize the data in the following structured JSON format:\" + cvStructure},\n",
    "                {\"role\": \"user\", \"content\": \"The fields skills, certifications_and_courses, and system_knowledge should only contain a list of values and should not contain records\"},\n",
    "                {\"role\": \"user\", \"content\": \"The fields skills refers to 'soft skills' and should contain values like 'teamwork', 'communication', 'leadership', etc.\"},\n",
    "                {\"role\": \"user\", \"content\": \"The fields systems_knowledge refers to knowledge of software, tools, or systems and should contain values like 'Microsoft Office', 'Python', 'Salesforce', etc.\"},\n",
    "                {\"role\": \"user\", \"content\": \"The field proficiency in languages should be set to one of the following values: basic, intermediate, advanced, full professional proficiency\"},\n",
    "                {\"role\": \"user\", \"content\": \"education and working_experiences field sort_order_newest_to_oldest should be set to 0 for the most recent record and should be incremented by 1 for each subsequent record\"},\n",
    "                {\"role\": \"user\", \"content\": \"education and working_experiences field format for start_date_YYYY and end_date_YYYY should be YYYY\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Create the response object\n",
    "    response_object = {\n",
    "        \"filename\": filename,\n",
    "        \"cv\": completion.choices[0].message.content\n",
    "    }\n",
    "\n",
    "    # Append the response object to the list of existing responses\n",
    "    existing_responses.append(response_object)\n",
    "\n",
    "    # Save the responses to the output file after each completion\n",
    "    with open(json_output_path, 'w') as outfile:\n",
    "        json.dump(existing_responses, outfile, indent=4)\n",
    "    \n",
    "    print(f\"Processed {filename} and saved the response.\")\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Structure for Job Position Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "structure = {\n",
    "  \"JobTitle\": \"\",\n",
    "  \"Department\": \"\",\n",
    "  \"ReportsTo\": \"\",\n",
    "  \"JobPurpose\": \"\",\n",
    "  \"KeyResponsibilities\": [],\n",
    "  \"WorkModality\": \"\",\n",
    "  \"AdditionalDetails\": \"\",\n",
    "  \"Qualifications\": {\n",
    "    \"education\": [],\n",
    "    \"work_experience\": [],\n",
    "    \"skills\": [],\n",
    "    \"certifications_and_courses\": [],\n",
    "    \"languages\": [\n",
    "        {\n",
    "            \"language\": \"\",\n",
    "            \"profieciency\": \"\"\n",
    "        }\n",
    "    ],\n",
    "    \"systems_knowledge\": []\n",
    "  }\n",
    "}\n",
    "\n",
    "positionDescriptionStructure = json.dumps(structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position description OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been successfully saved to ./Candidates Analysis/001_Analysis/Results/OCR_Position.json\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "# Define the folder path\n",
    "folder_path_position = \"./Candidates Analysis/\" + analysis_folder + \"/Position\"\n",
    "\n",
    "# Initialize a variable to store the extracted text\n",
    "extracted_data = None\n",
    "\n",
    "# Load only the first PDF file found in the folder\n",
    "for filename in os.listdir(folder_path_position):\n",
    "    if filename.endswith(\".pdf\"):  # Process only PDF files\n",
    "        file_path = os.path.join(folder_path_position, filename)\n",
    "        \n",
    "        # Open the PDF file\n",
    "        doc = fitz.open(file_path)\n",
    "        \n",
    "        # Extract text from each page\n",
    "        text = \"\"\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            text += page.get_text()\n",
    "        \n",
    "        # Store the extracted text in a dictionary with the filename as key\n",
    "        extracted_data = {\n",
    "            \"filename\": filename,\n",
    "            \"content\": text\n",
    "        }\n",
    "        \n",
    "        # Break the loop after processing the first file\n",
    "        break\n",
    "\n",
    "# If a file was processed, convert the dictionary to JSON format and save it\n",
    "if extracted_data:\n",
    "    extracted_json = json.dumps(extracted_data, indent=4)\n",
    "\n",
    "    # Define the output path to save the JSON file in the same location as the Position folder\n",
    "    output_json_path = results_folder_path + \"/OCR_Position.json\"\n",
    "\n",
    "    # Save the JSON data to a file (this will overwrite the file if it already exists)\n",
    "    with open(output_json_path, \"w\") as json_file:\n",
    "        json_file.write(extracted_json)\n",
    "\n",
    "    print(f\"JSON data has been successfully saved to {output_json_path}\")\n",
    "else:\n",
    "    print(\"No PDF files found in the specified folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position description LLM normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Position.pdf\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "import sys\n",
    "\n",
    "\n",
    "# Temporarily add the parent directory to the system path to import Constants\n",
    "sys.path.append(\"..\")\n",
    "import Constants\n",
    "sys.path.remove(\"..\")\n",
    "\n",
    "# Initialize OpenAI client with the API key from Constants\n",
    "client = OpenAI(api_key=Constants.OpenAIKey)\n",
    "\n",
    "# Define the paths for the JSON files\n",
    "json_path_OCR_Position = results_folder_path + \"/OCR_Position.json\"\n",
    "json_path_LLM_Position = results_folder_path + \"/LLM_Position.json\"\n",
    "\n",
    "# Load the OCR results from the JSON file\n",
    "with open(json_path_OCR_Position, 'r') as file:\n",
    "    ocr_results = json.load(file)\n",
    "\n",
    "# Check if the OCR results are empty\n",
    "if not ocr_results:\n",
    "    print(\"No data found in OCR results.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Take the first item from OCR results for processing\n",
    "filename = ocr_results['filename']\n",
    "content = ocr_results['content']\n",
    "\n",
    "\n",
    "# Interact with OpenAI's API\n",
    "completion = client.chat.completions.create(\n",
    "    model=gptModel,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant whose job is to perfectly understand the following data:\" + content},\n",
    "        {\"role\": \"user\", \"content\": \"You need to summarize the data in the following structured JSON format:\" + positionDescriptionStructure}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the response object\n",
    "response_object = {\n",
    "    \"filename\": filename,\n",
    "    \"position\": completion.choices[0].message.content\n",
    "}\n",
    "\n",
    "# Save the response to the output file (overwriting any existing file)\n",
    "with open(json_path_LLM_Position, 'w') as outfile:\n",
    "    json.dump(response_object, outfile, indent=4)\n",
    "\n",
    "print(f\"Processed {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Structure for Candidate Evaluation\n",
    "\n",
    "This script defines a JSON structure designed for evaluating job candidates across several dimensions. Each dimension, such as Education, Work Experience, Skills, Certifications and Courses, Languages, and General Assessment, is represented as an object within a \"dimensions\" list. \n",
    "\n",
    "This structured format allows for systematic assessment of candidates, ensuring a comprehensive evaluation process. The structure is serialized into a JSON-formatted string using `json.dumps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "structure = {\n",
    "    \"dimensions\": [\n",
    "        {\n",
    "            \"name\": \"education\",\n",
    "            \"description\": \"Assessment of the candidate's highest level of education, field of study, and relevance to the position.\",\n",
    "            \"accepted_values\": \"Integer, from 0 (Not a match) to 100 (Complete match), using only multiples of 10 (0, 10, 20, ..., 100)\",\n",
    "            \"value\": 0,\n",
    "            \"reasoning\": \"\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"work_experience\",\n",
    "            \"description\": \"Evaluation of previous job roles, duration of employment, responsibilities held, and achievements in those roles.\",\n",
    "            \"accepted_values\": \"Integer, from 0 (Not a match) to 100 (Complete match), using only multiples of 10 (0, 10, 20, ..., 100)\",\n",
    "            \"value\": 0,\n",
    "            \"reasoning\": \"\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"skills\",\n",
    "            \"description\": \"Identification of hard skills (technical abilities, certifications) and soft skills (communication, leadership) relevant to the job.\",\n",
    "            \"accepted_values\": \"Integer, from 0 (Not a match) to 100 (Complete match), using only multiples of 10 (0, 10, 20, ..., 100)\",\n",
    "            \"value\": 0,\n",
    "            \"reasoning\": \"\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"certifications_and_courses\",\n",
    "            \"description\": \"Listing of additional certifications or courses completed that are pertinent to the job role, indicating continuous learning.\",\n",
    "            \"accepted_values\": \"Integer, from 0 (Not a match) to 100 (Complete match), using only multiples of 10 (0, 10, 20, ..., 100)\",\n",
    "            \"value\": 0,\n",
    "            \"reasoning\": \"\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"languages\",\n",
    "            \"description\": \"The candidate posses the required languages for the job role\",\n",
    "            \"accepted_values\": \"Integer, from 0 (Not a match) to 100 (Complete match), using only multiples of 10 (0, 10, 20, ..., 100)\",\n",
    "            \"value\": 0,\n",
    "            \"reasoning\": \"\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"systems_knowledge\",\n",
    "            \"description\": \"Evaluation of the candidate's familiarity with specific systems or tools required for the job role.\",\n",
    "            \"accepted_values\": \"Integer, from 0 (Not a match) to 100 (Complete match), using only multiples of 10 (0, 10, 20, ..., 100)\",\n",
    "            \"value\": 0,\n",
    "            \"reasoning\": \"\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"general_assessment\",\n",
    "            \"description\": \"General assessment of the candidate's fit for the job role including a gap analysis of what was missing to be a perfect match.\",\n",
    "            \"accepted_values\": \"Integer, from 0 (Not a match) to 100 (Complete match), using only multiples of 10 (0, 10, 20, ..., 100)\",\n",
    "            \"value\": 0,\n",
    "            \"reasoning\": \"\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "resultStructure = json.dumps(structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for Alex_Johnson_CV.pdf already exists in LLM_Analysis.json. Skipping...\n",
      "Result for Emma_Brown_CV.pdf already exists in LLM_Analysis.json. Skipping...\n",
      "Result for John_Carter_CV.pdf already exists in LLM_Analysis.json. Skipping...\n",
      "Result for Maria_Thompson_CV.pdf already exists in LLM_Analysis.json. Skipping...\n",
      "Result for Michael_Smith_CV.pdf already exists in LLM_Analysis.json. Skipping...\n",
      "No new results to save.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Temporarily add the parent directory to the system path to import Constants\n",
    "sys.path.append(\"..\")\n",
    "import Constants\n",
    "sys.path.remove(\"..\")\n",
    "\n",
    "# Initialize OpenAI client with the API key from Constants\n",
    "client = OpenAI(api_key=Constants.OpenAIKey)\n",
    "\n",
    "# Define the paths for the JSON files\n",
    "json_path_LLM_Position = results_folder_path + \"/LLM_Position.json\"\n",
    "json_path_LLM_Normalized_CV = results_folder_path + \"/LLM_Normalized_CV.json\"\n",
    "json_path_LLM_Result =  results_folder_path + \"/LLM_Analysis.json\"\n",
    "\n",
    "# Load the JSON data from the Position file\n",
    "with open(json_path_LLM_Position, 'r') as file:\n",
    "    position_data = json.load(file)\n",
    "\n",
    "# Extract the \"position\" field\n",
    "position = position_data.get('position', None)\n",
    "\n",
    "# Ensure the position data is available\n",
    "if not position:\n",
    "    raise ValueError(\"The 'position' field is missing in the Position JSON file.\")\n",
    "\n",
    "# Load the JSON data from the Normalized CV file\n",
    "with open(json_path_LLM_Normalized_CV, 'r') as file:\n",
    "    cv_data = json.load(file)\n",
    "\n",
    "# Load existing results or initialize an empty list if the file doesn't exist\n",
    "if os.path.exists(json_path_LLM_Result):\n",
    "    with open(json_path_LLM_Result, 'r') as result_file:\n",
    "        try:\n",
    "            existing_results = json.load(result_file)\n",
    "        except json.JSONDecodeError:\n",
    "            existing_results = []\n",
    "else:\n",
    "    existing_results = []\n",
    "\n",
    "# Initialize a list to store new responses\n",
    "new_responses = []\n",
    "\n",
    "# Iterate through each CV object\n",
    "for cv in cv_data:\n",
    "    filename = cv.get('filename')\n",
    "\n",
    "    # Check if the filename already exists in the results\n",
    "    if any(result['filename'] == filename for result in existing_results):\n",
    "        print(f\"Result for {filename} already exists in LLM_Analysis.json. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Prepare the CV data for the OpenAI request\n",
    "    candidate_cv = cv.get('cv', None)\n",
    "    if not candidate_cv:\n",
    "        print(f\"No CV data found for {filename}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Make the request to OpenAI\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=gptModel,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You need to perfectly understand the following position description in JSON: \" + position},\n",
    "                {\"role\": \"system\", \"content\": \"You are an amazing non-biased recruiter whose job is to perfectly understand the following candidate data in JSON: \" + candidate_cv},\n",
    "                {\"role\": \"user\", \"content\": \"Based on the previous information, you need to assess a candidate's fit to the position and output the information in EXACTLY this JSON format:\" + resultStructure},\n",
    "                {\"role\": \"user\", \"content\": \"The value field should be an integer, from 0 (Not a match) to 100 (Complete match), using only multiples of 10 (0, 10, 20, ..., 100)\"},\n",
    "                {\"role\": \"user\", \"content\": \"The reasoning field should be a string, explaining why the candidate is a match or not including a gap analysis of what was missing to be a complete match\"}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Append the completion result to the new_responses list\n",
    "        new_responses.append({\n",
    "            \"filename\": filename,\n",
    "            \"content\": completion.choices[0].message.content\n",
    "        })\n",
    "        \n",
    "        print(f\"Result prepared for {filename}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for {filename}: {str(e)}\")\n",
    "\n",
    "# After processing all CVs, append the new responses to the existing results and save\n",
    "if new_responses:\n",
    "    existing_results.extend(new_responses)\n",
    "    with open(json_path_LLM_Result, \"w\") as json_file:\n",
    "        json.dump(existing_results, json_file, indent=4)\n",
    "    print(\"All new results have been saved.\")\n",
    "else:\n",
    "    print(\"No new results to save.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
